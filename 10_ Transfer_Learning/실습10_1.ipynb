{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helpful-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "count = 0\n",
    "videoFile = \"../video/Tom and Jerry.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5)\n",
    "\n",
    "x=1\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    frameId = cap.get(1)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = \"./picture/frame%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "cap.release()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "rolled-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('../dataset/mapping.csv')\n",
    "data.head()\n",
    "\n",
    "X = []\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('./picture/' + img_name)\n",
    "    X.append(img)\n",
    "    \n",
    "X = np.array(X)\n",
    "\n",
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)\n",
    "\n",
    "image = []\n",
    "for i in range(0, X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224, 224)).astype(int)\n",
    "    image.append(a)  \n",
    "X = np.array(image)\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adapted-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 25,694,211\n",
      "Trainable params: 25,694,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 208 samples, validate on 90 samples\n",
      "Epoch 1/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 1.0027 - accuracy: 0.5288 - val_loss: 0.6714 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.3509 - accuracy: 0.9087 - val_loss: 0.4757 - val_accuracy: 0.8111\n",
      "Epoch 3/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.1506 - accuracy: 0.9663 - val_loss: 0.3777 - val_accuracy: 0.8778\n",
      "Epoch 4/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0831 - accuracy: 0.9904 - val_loss: 0.3003 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0525 - accuracy: 0.9904 - val_loss: 0.2742 - val_accuracy: 0.8889\n",
      "Epoch 6/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0384 - accuracy: 0.9904 - val_loss: 0.2685 - val_accuracy: 0.8889\n",
      "Epoch 7/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0320 - accuracy: 0.9952 - val_loss: 0.2892 - val_accuracy: 0.8778\n",
      "Epoch 8/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0245 - accuracy: 0.9952 - val_loss: 0.2849 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0232 - accuracy: 0.9952 - val_loss: 0.2767 - val_accuracy: 0.9111\n",
      "Epoch 10/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.2967 - val_accuracy: 0.8889\n",
      "Epoch 11/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0224 - accuracy: 0.9904 - val_loss: 0.2577 - val_accuracy: 0.9111\n",
      "Epoch 12/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.2630 - val_accuracy: 0.9111\n",
      "Epoch 13/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.3070 - val_accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.3008 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0175 - accuracy: 0.9904 - val_loss: 0.2699 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0169 - accuracy: 0.9904 - val_loss: 0.2737 - val_accuracy: 0.8889\n",
      "Epoch 17/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.2640 - val_accuracy: 0.9111\n",
      "Epoch 18/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0147 - accuracy: 0.9904 - val_loss: 0.2686 - val_accuracy: 0.8889\n",
      "Epoch 19/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0137 - accuracy: 0.9904 - val_loss: 0.2670 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "208/208 [==============================] - 5s 22ms/step - loss: 0.0142 - accuracy: 0.9904 - val_loss: 0.2703 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.2578 - val_accuracy: 0.9111\n",
      "Epoch 22/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.2887 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.2988 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.2674 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0117 - accuracy: 0.9904 - val_loss: 0.2643 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "208/208 [==============================] - 5s 22ms/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 0.2561 - val_accuracy: 0.9222\n",
      "Epoch 27/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.2614 - val_accuracy: 0.9111\n",
      "Epoch 28/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.3327 - val_accuracy: 0.8556\n",
      "Epoch 29/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.2929 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0131 - accuracy: 0.9904 - val_loss: 0.2564 - val_accuracy: 0.9111\n",
      "Epoch 31/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0119 - accuracy: 0.9952 - val_loss: 0.2664 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0101 - accuracy: 0.9904 - val_loss: 0.2854 - val_accuracy: 0.8778\n",
      "Epoch 33/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.2888 - val_accuracy: 0.8778\n",
      "Epoch 34/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0159 - accuracy: 0.9904 - val_loss: 0.2562 - val_accuracy: 0.9111\n",
      "Epoch 35/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 0.2881 - val_accuracy: 0.8778\n",
      "Epoch 36/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.2967 - val_accuracy: 0.8778\n",
      "Epoch 37/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0156 - accuracy: 0.9904 - val_loss: 0.2530 - val_accuracy: 0.9222\n",
      "Epoch 38/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 0.2718 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0108 - accuracy: 0.9952 - val_loss: 0.2934 - val_accuracy: 0.8778\n",
      "Epoch 40/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.2908 - val_accuracy: 0.8778\n",
      "Epoch 41/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9222\n",
      "Epoch 42/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 0.2423 - val_accuracy: 0.9222\n",
      "Epoch 43/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.2954 - val_accuracy: 0.8778\n",
      "Epoch 44/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.3320 - val_accuracy: 0.8556\n",
      "Epoch 45/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.2776 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0101 - accuracy: 0.9952 - val_loss: 0.2741 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0095 - accuracy: 0.9904 - val_loss: 0.2842 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0110 - accuracy: 0.9904 - val_loss: 0.2695 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0088 - accuracy: 0.9952 - val_loss: 0.2900 - val_accuracy: 0.8778\n",
      "Epoch 50/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0117 - accuracy: 0.9904 - val_loss: 0.2788 - val_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0097 - accuracy: 0.9952 - val_loss: 0.3071 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.2948 - val_accuracy: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0083 - accuracy: 0.9904 - val_loss: 0.2566 - val_accuracy: 0.9111\n",
      "Epoch 54/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0117 - accuracy: 0.9904 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.2414 - val_accuracy: 0.9222\n",
      "Epoch 56/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.3892 - val_accuracy: 0.8556\n",
      "Epoch 57/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0259 - accuracy: 0.9952 - val_loss: 0.4159 - val_accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 0.2851 - val_accuracy: 0.8889\n",
      "Epoch 59/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0195 - accuracy: 0.9904 - val_loss: 0.2446 - val_accuracy: 0.9222\n",
      "Epoch 60/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0088 - accuracy: 0.9952 - val_loss: 0.2921 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0108 - accuracy: 0.9952 - val_loss: 0.2835 - val_accuracy: 0.8889\n",
      "Epoch 62/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0094 - accuracy: 0.9952 - val_loss: 0.2754 - val_accuracy: 0.8889\n",
      "Epoch 63/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.2453 - val_accuracy: 0.9222\n",
      "Epoch 64/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0182 - accuracy: 0.9904 - val_loss: 0.2949 - val_accuracy: 0.8778\n",
      "Epoch 65/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0101 - accuracy: 0.9904 - val_loss: 0.2873 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0108 - accuracy: 0.9952 - val_loss: 0.3110 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0091 - accuracy: 0.9904 - val_loss: 0.2784 - val_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 0.2836 - val_accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0098 - accuracy: 0.9952 - val_loss: 0.2832 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0077 - accuracy: 0.9952 - val_loss: 0.3138 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0106 - accuracy: 0.9952 - val_loss: 0.3081 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0081 - accuracy: 0.9952 - val_loss: 0.2769 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 0.2660 - val_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0091 - accuracy: 0.9952 - val_loss: 0.2875 - val_accuracy: 0.8889\n",
      "Epoch 75/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0097 - accuracy: 0.9952 - val_loss: 0.2989 - val_accuracy: 0.8778\n",
      "Epoch 76/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 0.2726 - val_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0096 - accuracy: 0.9904 - val_loss: 0.2789 - val_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0084 - accuracy: 0.9952 - val_loss: 0.2755 - val_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0103 - accuracy: 0.9904 - val_loss: 0.2883 - val_accuracy: 0.8889\n",
      "Epoch 80/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0096 - accuracy: 0.9904 - val_loss: 0.2864 - val_accuracy: 0.8889\n",
      "Epoch 81/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0115 - accuracy: 0.9952 - val_loss: 0.2586 - val_accuracy: 0.9222\n",
      "Epoch 82/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0095 - accuracy: 0.9952 - val_loss: 0.2964 - val_accuracy: 0.8778\n",
      "Epoch 83/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.3550 - val_accuracy: 0.8556\n",
      "Epoch 84/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0109 - accuracy: 0.9952 - val_loss: 0.2711 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0082 - accuracy: 0.9952 - val_loss: 0.2600 - val_accuracy: 0.9222\n",
      "Epoch 86/100\n",
      "208/208 [==============================] - 4s 22ms/step - loss: 0.0122 - accuracy: 0.9904 - val_loss: 0.2864 - val_accuracy: 0.8889\n",
      "Epoch 87/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 0.2889 - val_accuracy: 0.8889\n",
      "Epoch 88/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0077 - accuracy: 0.9952 - val_loss: 0.3368 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.3218 - val_accuracy: 0.8667\n",
      "Epoch 90/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0251 - accuracy: 0.9904 - val_loss: 0.2455 - val_accuracy: 0.9222\n",
      "Epoch 91/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.2568 - val_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.2995 - val_accuracy: 0.8778\n",
      "Epoch 93/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0090 - accuracy: 0.9952 - val_loss: 0.3296 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0084 - accuracy: 0.9952 - val_loss: 0.2939 - val_accuracy: 0.8889\n",
      "Epoch 95/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0086 - accuracy: 0.9952 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0096 - accuracy: 0.9952 - val_loss: 0.2774 - val_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "208/208 [==============================] - 5s 24ms/step - loss: 0.0089 - accuracy: 0.9952 - val_loss: 0.3015 - val_accuracy: 0.8778\n",
      "Epoch 98/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0081 - accuracy: 0.9952 - val_loss: 0.3012 - val_accuracy: 0.8778\n",
      "Epoch 99/100\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 0.0097 - accuracy: 0.9952 - val_loss: 0.3053 - val_accuracy: 0.8778\n",
      "Epoch 100/100\n",
      "208/208 [==============================] - 6s 27ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.2571 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2121ffe2908>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape\n",
    "\n",
    "X_train = X_train.reshape(208, 7*7*512)\n",
    "X_valid = X_valid.reshape(90, 7*7*512)\n",
    "\n",
    "train = X_train/X_train.max()\n",
    "X_valid = X_valid/X_train.max()\n",
    "\n",
    "#i. Building the model\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))\n",
    "model.add(Dense(units=1024, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#ii. Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#iii. Training the model\n",
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "streaming-facial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Tom and Jerry3.mp4 이미지 추출\n",
    "\n",
    "count = 0\n",
    "videoFile = \"../video/Tom and Jerry 3.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5)\n",
    "\n",
    "x=1\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    frameId = cap.get(1)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = \"./picture/test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "cap.release()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "radical-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../dataset/testing.csv')\n",
    "\n",
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('./picture/' + img_name)\n",
    "    test_image.append(img)    \n",
    "test_img = np.array(test_image)\n",
    "\n",
    "test_image = []\n",
    "for i in range(0, test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224, 224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "otherwise-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the images\n",
    "test_image = preprocess_input(test_image)\n",
    "\n",
    "#extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "\n",
    "#converting the image to 1-D form\n",
    "test_image = test_image.reshape(186, 7*7*512)\n",
    "\n",
    "#zero centered images\n",
    "test_image = test_image/test_image.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "proved-price",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208 samples, validate on 90 samples\n",
      "Epoch 1/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 1.3530 - accuracy: 0.4038 - val_loss: 1.0950 - val_accuracy: 0.3889\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.09504, saving model to weights.best.hdf5\n",
      "Epoch 2/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 1.2836 - accuracy: 0.3269 - val_loss: 1.0320 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.09504 to 1.03196, saving model to weights.best.hdf5\n",
      "Epoch 3/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 1.1699 - accuracy: 0.4663 - val_loss: 1.1297 - val_accuracy: 0.3889\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.03196\n",
      "Epoch 4/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 1.1059 - accuracy: 0.4135 - val_loss: 0.9514 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03196 to 0.95141, saving model to weights.best.hdf5\n",
      "Epoch 5/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 1.0107 - accuracy: 0.5337 - val_loss: 0.8870 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.95141 to 0.88696, saving model to weights.best.hdf5\n",
      "Epoch 6/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.8830 - accuracy: 0.6346 - val_loss: 0.8575 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.88696 to 0.85747, saving model to weights.best.hdf5\n",
      "Epoch 7/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.7370 - accuracy: 0.6827 - val_loss: 0.6729 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85747 to 0.67290, saving model to weights.best.hdf5\n",
      "Epoch 8/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.5730 - accuracy: 0.7885 - val_loss: 0.5689 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.67290 to 0.56894, saving model to weights.best.hdf5\n",
      "Epoch 9/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.4021 - accuracy: 0.8510 - val_loss: 0.4467 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56894 to 0.44670, saving model to weights.best.hdf5\n",
      "Epoch 10/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.2512 - accuracy: 0.9519 - val_loss: 0.3681 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44670 to 0.36807, saving model to weights.best.hdf5\n",
      "Epoch 11/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.2087 - accuracy: 0.9279 - val_loss: 0.3354 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36807 to 0.33540, saving model to weights.best.hdf5\n",
      "Epoch 12/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.1243 - accuracy: 0.9760 - val_loss: 0.2730 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33540 to 0.27297, saving model to weights.best.hdf5\n",
      "Epoch 13/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0667 - accuracy: 0.9952 - val_loss: 0.3155 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27297\n",
      "Epoch 14/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0607 - accuracy: 0.9904 - val_loss: 0.3281 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27297\n",
      "Epoch 15/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0558 - accuracy: 0.9904 - val_loss: 0.2674 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27297 to 0.26736, saving model to weights.best.hdf5\n",
      "Epoch 16/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0303 - accuracy: 0.9952 - val_loss: 0.2442 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26736 to 0.24415, saving model to weights.best.hdf5\n",
      "Epoch 17/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0503 - accuracy: 0.9856 - val_loss: 0.2825 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24415\n",
      "Epoch 18/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0229 - accuracy: 0.9952 - val_loss: 0.2811 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24415\n",
      "Epoch 19/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.3303 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24415\n",
      "Epoch 20/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.2521 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24415\n",
      "Epoch 21/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.2328 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24415 to 0.23284, saving model to weights.best.hdf5\n",
      "Epoch 22/100\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.23284\n",
      "Epoch 23/100\n",
      "208/208 [==============================] - 5s 22ms/step - loss: 0.0481 - accuracy: 0.9904 - val_loss: 0.3156 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.23284\n",
      "Epoch 24/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.2781 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.23284\n",
      "Epoch 25/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 0.2306 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23284 to 0.23061, saving model to weights.best.hdf5\n",
      "Epoch 26/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.23061\n",
      "Epoch 27/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.23061\n",
      "Epoch 28/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.23061\n",
      "Epoch 29/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.2568 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.23061\n",
      "Epoch 30/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0240 - accuracy: 0.9952 - val_loss: 0.2097 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.23061 to 0.20973, saving model to weights.best.hdf5\n",
      "Epoch 31/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0313 - accuracy: 0.9952 - val_loss: 0.2840 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20973\n",
      "Epoch 32/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0181 - accuracy: 0.9904 - val_loss: 0.3523 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20973\n",
      "Epoch 33/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0285 - accuracy: 0.9952 - val_loss: 0.2972 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20973\n",
      "Epoch 34/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20973\n",
      "Epoch 35/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0156 - accuracy: 0.9904 - val_loss: 0.2260 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.20973\n",
      "Epoch 36/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.2344 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.20973\n",
      "Epoch 37/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.2878 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20973\n",
      "Epoch 38/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.20973\n",
      "Epoch 39/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.3295 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.20973\n",
      "Epoch 40/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.3042 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20973\n",
      "Epoch 41/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20973\n",
      "Epoch 42/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.20973\n",
      "Epoch 43/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0090 - accuracy: 0.9952 - val_loss: 0.2620 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.20973\n",
      "Epoch 44/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.2554 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.20973\n",
      "Epoch 45/100\n",
      "208/208 [==============================] - 4s 18ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.2708 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.20973\n",
      "Epoch 46/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.20973\n",
      "Epoch 47/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0277 - accuracy: 0.9904 - val_loss: 0.2707 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.20973\n",
      "Epoch 48/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0110 - accuracy: 0.9904 - val_loss: 0.3111 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.20973\n",
      "Epoch 49/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.20973\n",
      "Epoch 50/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.2422 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.20973\n",
      "Epoch 51/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0149 - accuracy: 0.9904 - val_loss: 0.2380 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.20973\n",
      "Epoch 52/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0186 - accuracy: 0.9904 - val_loss: 0.2327 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20973\n",
      "Epoch 53/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0089 - accuracy: 0.9952 - val_loss: 0.2429 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20973\n",
      "Epoch 54/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0090 - accuracy: 0.9952 - val_loss: 0.2758 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20973\n",
      "Epoch 55/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0211 - accuracy: 0.9904 - val_loss: 0.2774 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20973\n",
      "Epoch 56/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.3451 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20973\n",
      "Epoch 57/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0169 - accuracy: 0.9904 - val_loss: 0.4106 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20973\n",
      "Epoch 58/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.2848 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20973\n",
      "Epoch 59/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20973\n",
      "Epoch 60/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0152 - accuracy: 0.9904 - val_loss: 0.2732 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20973\n",
      "Epoch 61/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.2737 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20973\n",
      "Epoch 62/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0187 - accuracy: 0.9904 - val_loss: 0.2864 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20973\n",
      "Epoch 63/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.3087 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20973\n",
      "Epoch 64/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 0.3120 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20973\n",
      "Epoch 65/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0109 - accuracy: 0.9952 - val_loss: 0.3058 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20973\n",
      "Epoch 66/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.3031 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20973\n",
      "Epoch 67/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20973\n",
      "Epoch 68/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0129 - accuracy: 0.9904 - val_loss: 0.2525 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20973\n",
      "Epoch 69/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 0.2583 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20973\n",
      "Epoch 70/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20973\n",
      "Epoch 71/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.3408 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20973\n",
      "Epoch 72/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0086 - accuracy: 0.9952 - val_loss: 0.3053 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20973\n",
      "Epoch 73/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20973\n",
      "Epoch 74/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20973\n",
      "Epoch 75/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 0.2884 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20973\n",
      "Epoch 76/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20973\n",
      "Epoch 77/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0121 - accuracy: 0.9952 - val_loss: 0.3301 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20973\n",
      "Epoch 78/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.2798 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20973\n",
      "Epoch 79/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20973\n",
      "Epoch 80/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0106 - accuracy: 0.9952 - val_loss: 0.2454 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20973\n",
      "Epoch 81/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0146 - accuracy: 0.9904 - val_loss: 0.2514 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20973\n",
      "Epoch 82/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 0.3575 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20973\n",
      "Epoch 83/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0205 - accuracy: 0.9904 - val_loss: 0.4428 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20973\n",
      "Epoch 84/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 0.3808 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20973\n",
      "Epoch 85/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0122 - accuracy: 0.9904 - val_loss: 0.2871 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20973\n",
      "Epoch 86/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0130 - accuracy: 0.9904 - val_loss: 0.2882 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20973\n",
      "Epoch 87/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0131 - accuracy: 0.9904 - val_loss: 0.2604 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20973\n",
      "Epoch 88/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.3066 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20973\n",
      "Epoch 89/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.3264 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20973\n",
      "Epoch 90/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0120 - accuracy: 0.9952 - val_loss: 0.2751 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20973\n",
      "Epoch 91/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0167 - accuracy: 0.9904 - val_loss: 0.2547 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20973\n",
      "Epoch 92/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0106 - accuracy: 0.9952 - val_loss: 0.2808 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20973\n",
      "Epoch 93/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0245 - accuracy: 0.9904 - val_loss: 0.3355 - val_accuracy: 0.8778\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20973\n",
      "Epoch 94/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.3226 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20973\n",
      "Epoch 95/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0076 - accuracy: 0.9952 - val_loss: 0.2614 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20973\n",
      "Epoch 96/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0179 - accuracy: 0.9904 - val_loss: 0.2728 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20973\n",
      "Epoch 97/100\n",
      "208/208 [==============================] - 4s 21ms/step - loss: 0.0119 - accuracy: 0.9952 - val_loss: 0.2528 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20973\n",
      "Epoch 98/100\n",
      "208/208 [==============================] - 4s 20ms/step - loss: 0.0062 - accuracy: 0.9952 - val_loss: 0.2419 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20973\n",
      "Epoch 99/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0241 - accuracy: 0.9904 - val_loss: 0.2400 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20973\n",
      "Epoch 100/100\n",
      "208/208 [==============================] - 4s 19ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20973\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512, ))) #input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) #hidden layer\n",
    "model.add(Dropout(0.5)) #adding dropout\n",
    "model.add(Dense(units=512, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list=[checkpoint]\n",
    "\n",
    "history = model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "lovely-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 2ms/step\n",
      "Real Test accuracy: 51.61%\n"
     ]
    }
   ],
   "source": [
    "test_y = np_utils.to_categorical(test.Class)\n",
    "\n",
    "scores = model.evaluate(test_image, test_y)\n",
    "\n",
    "print(\"Real Test %s: %2.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "weekly-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen time of None is 112 seconds\n",
      "The screen time of Jerry is 0 seconds\n",
      "The screen time of Tom is 74 seconds\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(test_image)\n",
    "\n",
    "print(\"The screen time of None is\", predictions[predictions==0].shape[0], \"seconds\")\n",
    "print(\"The screen time of Jerry is\", predictions[predictions==1].shape[0], \"seconds\")\n",
    "print(\"The screen time of Tom is\", predictions[predictions==2].shape[0], \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "painted-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, acc, marker='.', c=\"red\", label='Trainset_acc')\n",
    "plt.plot(x_len, val_acc, marker='.', c=\"lightcoral\", label='Testset_acc')\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"cornflowerblue\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-utilization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
